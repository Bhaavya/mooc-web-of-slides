<meta charset="utf-8"/>
<co-content>
 <h1 level="1">
  CS 410: Text Information Systems
 </h1>
 <h2 level="2">
  Course Description
 </h2>
 <p>
  The growth of “big data” created unprecedented opportunities to leverage computational and statistical approaches, which turn raw data into actionable knowledge that can support various application tasks. This is especially true for the optimization of decision making in virtually all application domains, such as health and medicine, security and safety, learning and education, scientific discovery, and business intelligence. This course covers general computational techniques for building intelligent text information systems to help users manage and make use of large amounts of text data in all kinds of applications.
 </p>
 <p>
  Text data include all data in the form of natural language text (e.g., English text or Chinese text), including all web pages, social media data such as tweets, news, scientific literature, emails, government documents, and many other kinds of enterprise data. Text data play an essential role in our lives. Since we communicate using natural languages, we produce and consume a large amount of text data every day covering all kinds of topics. The explosive growth of text data makes it impossible for people to consume all the relevant text data in a timely manner.
 </p>
 <p>
  The two main techniques to assist people in consuming, digesting, and making use of the text data are:
 </p>
 <ol bullettype="numbers">
  <li>
   <p>
    Text retrieval, which helps identify the most relevant text data to a particular problem from a large collection of text documents, thus avoiding processing a large number of non-relevant documents
   </p>
  </li>
  <li>
   <p>
    Text mining, which helps users further analyze and digest the found relevant text data and extract actionable knowledge for finishing a task
   </p>
  </li>
 </ol>
 <p>
  This course covers both text retrieval and text mining, so as to provide you with the opportunity to see the complete spectrum of techniques used in building an intelligent text information system. Building on two MOOCs covering the same topic and including a course project, this course enables you to learn the basic concepts, principles, and general techniques in text retrieval and mining, as well as gain hands-on experience with using software tools to develop interesting text data applications.
 </p>
 <h2 level="2">
  Course Goals and Objectives
 </h2>
 <p>
  Upon successful completion of this course, you will be able to:
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    Explain all the basic concepts in text retrieval and text mining.
   </p>
  </li>
  <li>
   <p>
    Explain the main ideas behind the major models and algorithms for text retrieval and text mining.
   </p>
  </li>
  <li>
   <p>
    Explain how the major models and algorithms for text retrieval and text mining work.
   </p>
  </li>
  <li>
   <p>
    Explain how to implement some of the commonly used algorithms for text retrieval and text mining.
   </p>
  </li>
  <li>
   <p>
    Explain how to evaluate applications of text retrieval and text mining.
   </p>
  </li>
 </ul>
 <h2 level="2">
  Textbook
 </h2>
 <p>
  There is not a required textbook for this course, but there are several optional readings suggested in each week's overview page. All readings listed in the weekly overview pages are optional and are primarily from the following textbook:
 </p>
 <p>
  Zhai, C. &amp; Massung, S. (2016).
  <em>
   Text data management and analysis: A practical introduction to information retrieval and text mining.
  </em>
  ACM Book Series. Morgan &amp; Claypool Publishers.
 </p>
 <h2 level="2">
  Course Outline
 </h2>
 <table columns="3" rows="17">
  <tr>
   <td>
    <p>
     <strong>
      Week
     </strong>
    </p>
   </td>
   <td>
    <p>
     <strong>
      Dates
     </strong>
    </p>
   </td>
   <td>
    <p>
     <strong>
      Topics
     </strong>
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 1
     </strong>
    </p>
   </td>
   <td>
    <p>
     August 27 -September 2
    </p>
   </td>
   <td>
    <p>
     Part of Speech tagging, syntactic analysis, semantic analysis, ambiguity, “bag of words” representation, push, pull, querying, browsing, probability ranking principle, relevance, vector space model, dot product, bit vector representation
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 2
     </strong>
    </p>
   </td>
   <td>
    <p>
     September 3 - 9
    </p>
   </td>
   <td>
    <p>
     Term frequency (TF), document frequency (DF), and inverse document frequency (IDF), TF transformation, pivoted length normalization, BM25, inverted index and postings, binary coding, unary coding, gamma-coding, d-gap, Zipf’s law
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 3
     </strong>
    </p>
   </td>
   <td>
    <p>
     September 10 - 16
    </p>
   </td>
   <td>
    <p>
     Cranfield evaluation methodology, precision and recall, average precision, mean average precision (MAP), geometric mean average precision (gMAP), reciprocal rank, mean reciprocal rank, F-measure , Normalized Discounted Cumulative Gain (nDCG), statistical significance test
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 4
     </strong>
    </p>
   </td>
   <td>
    <p>
     September 17 - 23
    </p>
   </td>
   <td>
    <p>
     p(R=1|q,d), query likelihood, p(q|d), statistical and unigram language models, maximum likelihood estimate, background, collection, and document language models, smoothing of unigram language models, relation between query likelihood and TF-IDF weighting, linear interpolation (i.e., Jelinek-Mercer) smoothing, Dirichlet Prior smoothing
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 5
     </strong>
    </p>
   </td>
   <td>
    <p>
     September 24 - 30
    </p>
   </td>
   <td>
    <p>
     Relevance feedback, pseudo-relevance feedback, implicit feedback, Rocchio feedback, Kullback-Leiber divergence (KL-divergence) retrieval function, mixture language model, scalability and efficiency, spams, crawler, focused crawling, and incremental crawling, Google File System (GFS), MapReduce, link analysis and anchor text, PageRank
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 6
     </strong>
    </p>
   </td>
   <td>
    <p>
     October 1 - 7
    </p>
   </td>
   <td>
    <p>
     Content-based filtering, collaborative filtering, Beta-Gamma threshold learning, linear utility , user profile, exploration-exploitation tradeoff, memory-based collaborative filtering, cold start
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 7
     </strong>
    </p>
   </td>
   <td>
    <p>
     October 8- 14
    </p>
   </td>
   <td>
    <p>
     Text representation (especially bag-of-words representation), context of a word, context similarity, paradigmatic relation, syntagmatic relation,
     <strong>
      Exam 1
     </strong>
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 8
     </strong>
    </p>
   </td>
   <td>
    <p>
     October 15 - 21
    </p>
   </td>
   <td>
    <p>
     Entropy, conditional entropy, mutual information, topics, coverage of topic , language model, generative model, unigram language model, word distribution, background language model, parameters of a probabilistic model, likelihood, Bayes rule, maximum likelihood estimation, prior and posterior distributions, Bayesian estimation &amp; inference, maximum a posteriori (MAP) estimate, prior model, posterior mode
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 9
     </strong>
    </p>
   </td>
   <td>
    <p>
     October 22 - 28
    </p>
   </td>
   <td>
    <p>
     Mixture model, component model, constraints on probabilities, Probabilistic Latent Semantic Analysis (PLSA), Expectation-Maximization (EM) algorithm, E-step and M-step, hidden variables, hill climbing, local maximum, Latent Dirichlet Allocation (LDA)
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 10
     </strong>
    </p>
   </td>
   <td>
    <p>
     October 29 - November 4
    </p>
   </td>
   <td>
    <p>
     Clustering, document clustering, term clustering, clustering bias, perspective of similarity, Hierarchical Agglomerative Clustering, k-Means, direction evaluation (of clustering), indirect evaluation (of clustering), text categorization, topic categorization, sentiment categorization, email routing , spam filtering, naïve Bayes classifier, smoothing
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 11
     </strong>
    </p>
   </td>
   <td>
    <p>
     November 5 - 11
    </p>
   </td>
   <td>
    <p>
     Generative classifier vs. discriminative classifier, training data, logistic regression, K-Nearest Neighbor classifier, classification accuracy, precision, recall, F measure, macro-averaging, micro-averaging, opinion holder, opinion target, sentiment, opinion representation, sentiment classification, features, n-grams, frequent patterns, overfitting
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 12
     </strong>
    </p>
   </td>
   <td>
    <p>
     November 12 - 18
    </p>
   </td>
   <td>
    <p>
     Text-based prediction, the “data mining loop”, context (of text data), contextual text mining, contextual probabilistic latent semantic analysis (CPLSA), views of a topic, coverage of topics, spatiotemporal trends of topics, event impact analysis, network-regularized topic modeling, NetPLSA, causal topics, iterative topic modeling with time series supervision
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 13
     </strong>
    </p>
   </td>
   <td>
    <p>
     November 19 - 25
    </p>
   </td>
   <td>
    <p>
     <em>
      Thanksgiving Break,
     </em>
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 14
     </strong>
    </p>
   </td>
   <td>
    <p>
     November 26 - December 2
    </p>
   </td>
   <td>
    <p>
     <strong>
      Exam 2
     </strong>
     ; Project work week.
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 15
     </strong>
    </p>
   </td>
   <td>
    <p>
     December 3 - 9
    </p>
   </td>
   <td>
    <p>
     No new content - work on your final project!
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 16
     </strong>
    </p>
   </td>
   <td>
    <p>
     December 10 - 13
    </p>
   </td>
   <td>
    <p>
     Final Project Presentation and Report Due End of Finals Week
    </p>
   </td>
  </tr>
 </table>
 <h2 level="2">
  Elements of This Course
 </h2>
 <ul bullettype="bullets">
  <li>
   <p>
    <strong>
     Lecture videos.
    </strong>
    Each week your instructor will teach you the concepts you need to know through a collection of short video lectures. You may either stream these videos for playback within the browser by clicking on their titles, or you can download each video for later offline playback by clicking the download icon.
    <strong>
     The videos usually total 1.5 to 2 hours each week
    </strong>
    , but you generally need to spend at least the same amount of time digesting the content in the videos. The actual amount of time needed to digest the content will naturally vary according to your background.
   </p>
  </li>
  <li>
   <p>
    <strong>
     Quizzes.
    </strong>
    Most weeks will include one for-credit quiz. You will have two attempts for each quiz, with your highest score used toward your final grade. Your top 10 quiz scores will be used to calculate your final grade (i.e., we will drop the two lowest quiz scores).
   </p>
  </li>
  <li>
   <p>
    <strong>
     Exams
    </strong>
    . This course will have two 2-hour exams. The exams are intended to test your understanding of the material you learn in the course and will contain questions similar to those seen in the weekly quizzes.
   </p>
  </li>
  <li>
   <p>
    <strong>
     Programming Assignments.
    </strong>
    The programming assignments for this course provide an opportunity for you to practice your programming skills and apply what you've learned in the course. Set aside about 2 hours each week to work on the programming assignment if you plan to finish it.
   </p>
  </li>
  <li>
   <p>
    <strong>
     Final Course Project.
    </strong>
    There will also be one culminating project due at the end of course. The first part will be individual and posted on Piazza, and the second part will require you to work in groups of at most three. The first part of the project will focus on simulation, while the second part will use methods from the course to perform data analysis and generate a written report.
   </p>
  </li>
 </ul>
 <p>
  <strong>
   Please note
  </strong>
  , in order to access course materials and
assignments, you will need to pay the Coursera fee ($158) for this course in
addition to the University of Illinois tuition.
 </p>
 <h2 level="2">
  Grading
 </h2>
 <p>
  Your final grade will be calculated based on the activities listed in the table below. As a note, the grade on Coursera will NOT accurately reflect your grade in the course.
 </p>
 <table columns="2" rows="6">
  <tr>
   <td>
    <p>
     <strong>
      Activity
     </strong>
    </p>
   </td>
   <td>
    <p>
     <strong>
      Percent of Final Grade
     </strong>
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     Quizzes
    </p>
   </td>
   <td>
    <p>
     25%
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     Programming Assignments
    </p>
   </td>
   <td>
    <p>
     25%
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     Course Project
    </p>
   </td>
   <td>
    <p>
     20%
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     Exam 1
    </p>
   </td>
   <td>
    <p>
     15%
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     Exam 2
    </p>
   </td>
   <td>
    <p>
     15%
    </p>
   </td>
  </tr>
 </table>
 <p>
 </p>
 <table columns="6" rows="4">
  <tr>
   <td>
    <p>
     <strong>
      Letter Grade
     </strong>
    </p>
   </td>
   <td>
    <p>
     <strong>
      Percent Needed
     </strong>
    </p>
   </td>
   <td>
    <p>
     <strong>
      Letter Grade
     </strong>
    </p>
   </td>
   <td>
    <p>
     <strong>
      Percent Needed
     </strong>
    </p>
   </td>
   <td>
    <p>
     <strong>
      Letter Grade
     </strong>
    </p>
   </td>
   <td>
    <p>
     <strong>
      Percent Needed
     </strong>
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      A+
     </strong>
    </p>
   </td>
   <td>
    <p>
     95
    </p>
   </td>
   <td>
    <p>
     <strong>
      B+
     </strong>
    </p>
   </td>
   <td>
    <p>
     80
    </p>
   </td>
   <td>
    <p>
     <strong>
      C
     </strong>
    </p>
   </td>
   <td>
    <p>
     60
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      A
     </strong>
    </p>
   </td>
   <td>
    <p>
     90
    </p>
   </td>
   <td>
    <p>
     <strong>
      B
     </strong>
    </p>
   </td>
   <td>
    <p>
     75
    </p>
   </td>
   <td>
    <p>
     <strong>
      D
     </strong>
    </p>
   </td>
   <td>
    <p>
     55
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      A-
     </strong>
    </p>
   </td>
   <td>
    <p>
     85
    </p>
   </td>
   <td>
    <p>
     <strong>
      B-
     </strong>
    </p>
   </td>
   <td>
    <p>
     70
    </p>
   </td>
   <td>
    <p>
     <strong>
      F
     </strong>
    </p>
   </td>
   <td>
    <p>
     &lt;55
    </p>
   </td>
  </tr>
 </table>
 <p>
  Your final grade will be
calculated based on the activities listed in the table below. Your official
final course grade will be listed in
  <a href="https://apps.uillinois.edu/selfservice/">
   Enterprise
  </a>
  . The course grade you see displayed in
Coursera may not match your official final course grade.
 </p>
 <h2 level="2">
  Additional Course Policies
 </h2>
 <h3 level="3">
  Student Code and Policies
 </h3>
 <p>
  A student at the University of Illinois at the Urbana‑Champaign campus is a member of a University community of which all members have at least the rights and responsibilities common to all citizens, free from institutional censorship; affiliation with the University as a student does not diminish the rights or responsibilities held by a student or any other community member as a citizen of larger communities of the state, the nation, and the world. See the
  <a href="http://studentcode.illinois.edu/index.html">
   University of Illinois Student Code
  </a>
  for more information.
 </p>
 <p>
  The CS department also maintains a policies handbook for graduate student. For more information, see the
  <a href="https://cs.illinois.edu/sites/default/files/images/CSGraduateStudentHandbook_web.15-16.pdf">
   Graduate Student Handbook
  </a>
  .
 </p>
 <p>
  Additionally, all Coursera learners are required to follow an
  <a href="https://learner.coursera.help/hc/en-us/articles/209818863-Coursera-Honor-Code">
   Honor Code
  </a>
  and a
  <a href="https://learner.coursera.help/hc/en-us/articles/208280036-Coursera-Code-of-Conduct">
   Code of Conduct
  </a>
  . Please review both of these items before commencing your studies.
 </p>
 <h3 level="3">
  Academic Integrity
 </h3>
 <p>
  All students are expected to abide by
  <a href="http://admin.illinois.edu/policy/code/article1_part4_1-401.html">
   the campus regulations on academic integrity found in the Student Code of Conduct
  </a>
  . These standards will be enforced and infractions of these rules will not be tolerated in this course. Sharing, copying, or providing any part of a homework solution or code is an infraction of the University’s rules on academic integrity. We will be actively looking for violations of this policy in homework and project submissions. Any violation will be punished as severely as possible with sanctions and penalties typically ranging from a failing grade on this assignment up to a failing grade in the course, including a letter of the offending infraction kept in the student's permanent university record.
 </p>
 <p>
  Again, a good rule of thumb:
  <em>
   Keep every typed word and piece of code your own
  </em>
  . If you think you are operating in a gray area, you probably are. If you would like clarification on specifics, please contact the course staff.
 </p>
 <h3 level="3">
  Disability Accommodations
 </h3>
 <p>
  Students with learning, physical, or other disabilities requiring assistance should contact the instructor as soon as possible. If you’re unsure if this applies to you or think it may, please contact the instructor and
  <a href="http://disability.illinois.edu/">
   Disability Resources and Educational Services (DRES)
  </a>
  as soon as possible. You can contact DRES at 1207 S. Oak Street, Champaign, via phone at (217) 333-1970, or via email at
  <a href="mailto:disability@illinois.edu">
   disability@illinois.edu
  </a>
  .
 </p>
 <h3 level="3">
  Late Policy
 </h3>
 <p>
  Late homework and homework by email will not be accepted by the TA or the instructors without prior instructor approval.
 </p>
 <p>
 </p>
 <p>
 </p>
 <p>
 </p>
 <p>
 </p>
 <p>
 </p>
</co-content>
<style>
 body {
    padding: 50px 85px 50px 85px;
}

table th, table td {
    border: 1px solid #e0e0e0;
    padding: 5px 20px;
    text-align: left;
}
input {
    margin: 10px;
}
}
th {
    font-weight: bold;
}
td, th {
    display: table-cell;
    vertical-align: inherit;
}
img {
    height: auto;
    max-width: 100%;
}
pre {
    display: block;
    margin: 20px;
    background: #424242;
    color: #fff;
    font-size: 13px;
    white-space: pre-wrap;
    padding: 9.5px;
    margin: 0 0 10px;
    border: 1px solid #ccc;
}
</style>
<script async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$$','$$'], ['$','$'] ],
      displayMath: [ ["\\[","\\]"] ],
      processEscapes: true
    }
  });
</script>
