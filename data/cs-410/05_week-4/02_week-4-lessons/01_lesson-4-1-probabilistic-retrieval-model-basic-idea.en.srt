1
00:00:00,086 --> 00:00:07,516
[SOUND]
This

2
00:00:07,516 --> 00:00:10,282
lecture is about
the Probabilistic Retrieval Model.

3
00:00:10,282 --> 00:00:11,805
In this lecture,

4
00:00:11,805 --> 00:00:17,806
we're going to continue the discussion
of the Text Retrieval Methods.

5
00:00:17,806 --> 00:00:22,942
We're going to look at another kind of
very different way to design ranking

6
00:00:22,942 --> 00:00:27,584
functions than the Vector Space Model
that we discussed before.

7
00:00:32,146 --> 00:00:36,589
In probabilistic models,
we define the ranking function,

8
00:00:36,589 --> 00:00:41,822
based on the probability that this
document is relevant to this query.

9
00:00:41,822 --> 00:00:46,802
In other words, we introduce
a binary random variable here.

10
00:00:46,802 --> 00:00:51,400
This is the variable R here.

11
00:00:51,400 --> 00:00:54,520
And we also assume that the query and

12
00:00:54,520 --> 00:00:59,830
the documents are all observations
from random variables.

13
00:01:00,920 --> 00:01:05,810
Note that in the vector-based models,
we assume they are vectors, but

14
00:01:05,810 --> 00:01:11,120
here we assume they are the data
observed from random variables.

15
00:01:11,120 --> 00:01:17,940
And so, the problem of retrieval becomes
to estimate the probability of relevance.

16
00:01:19,490 --> 00:01:23,060
In this category of models,
there are different variants.

17
00:01:23,060 --> 00:01:27,130
The classic probabilistic model has
led to the BM25 retrieval function,

18
00:01:27,130 --> 00:01:30,150
which we discussed in in
the vectors-based model

19
00:01:30,150 --> 00:01:33,570
because its a form is actually
similar to a backwards space model.

20
00:01:35,260 --> 00:01:40,180
In this lecture,
we will discuss another sub class in this

21
00:01:41,230 --> 00:01:45,550
P class called a language
modeling approaches to retrieval.

22
00:01:45,550 --> 00:01:50,150
In particular, we're going to discuss
the query likelihood retrieval model,

23
00:01:51,370 --> 00:01:55,330
which is one of the most effective
models in probabilistic models.

24
00:01:57,050 --> 00:02:01,840
There was also another line called
the divergence from randomness model

25
00:02:01,840 --> 00:02:04,970
which has led to the PL2 function,

26
00:02:06,440 --> 00:02:11,070
it's also one of the most effective
state of the art retrieval functions.

27
00:02:11,070 --> 00:02:16,847
In query likelihood, our assumption
is that this probability of relevance

28
00:02:16,847 --> 00:02:23,002
can be approximated by the probability
of query given a document and relevance.

29
00:02:23,002 --> 00:02:29,656
So intuitively, this probability just
captures the following probability.

30
00:02:29,656 --> 00:02:34,808
And that is if a user likes document d,
how likely would

31
00:02:34,808 --> 00:02:40,220
the user enter query q ,in
order to retrieve document d?

32
00:02:40,220 --> 00:02:47,680
So we assume that the user likes d,
because we have a relevance value here.

33
00:02:47,680 --> 00:02:52,610
And then we ask the question about how
likely we'll see this particular query

34
00:02:52,610 --> 00:02:53,250
from this user?

35
00:02:54,890 --> 00:02:56,508
So this is the basic idea.

36
00:02:56,508 --> 00:03:00,676
Now, to understand this idea,
let's take a look at the general idea or

37
00:03:00,676 --> 00:03:03,741
the basic idea of
Probabilistic Retrieval Models.

38
00:03:03,741 --> 00:03:09,150
So here, I listed some imagined
relevance status values or

39
00:03:09,150 --> 00:03:13,599
relevance judgments of queries and
documents.

40
00:03:13,599 --> 00:03:17,576
For example, in this line,

41
00:03:17,576 --> 00:03:24,546
it shows that q1 is a query
that the user typed in.

42
00:03:24,546 --> 00:03:28,043
And d1 is a document
that the user has seen.

43
00:03:28,043 --> 00:03:33,036
And 1 means the user thinks
d1 is relevant to q1.

44
00:03:33,036 --> 00:03:38,685
So this R here can be also approximated
by the click-through data that a search

45
00:03:38,685 --> 00:03:44,810
engine can collect by watching how you
interacted with the search results.

46
00:03:44,810 --> 00:03:47,990
So in this case, let's say
the user clicked on this document.

47
00:03:47,990 --> 00:03:49,000
So there's a 1 here.

48
00:03:50,080 --> 00:03:56,480
Similarly, the user clicked on d2 also,
so there is a 1 here.

49
00:03:56,480 --> 00:03:59,630
In other words,
d2 is assumed to be relevant to q1.

50
00:04:00,700 --> 00:04:05,080
On the other hand,
d3 is non-relevant, there's a 0 here.

51
00:04:07,430 --> 00:04:13,485
And d4 is non-relevant and then d5 is
again, relevant, and so on and so forth.

52
00:04:13,485 --> 00:04:17,860
And this part, maybe,
data collected from a different user.

53
00:04:17,860 --> 00:04:23,009
So this user typed in q1 and then found
that the d1 is actually not useful,

54
00:04:23,009 --> 00:04:26,170
so d1 is actually non-relevant.

55
00:04:26,170 --> 00:04:31,124
In contrast, here we see it's relevant.

56
00:04:31,124 --> 00:04:38,401
Or this could be the same query typed
in by the same user at different times.

57
00:04:38,401 --> 00:04:42,660
But d2 is also relevant, etc.

58
00:04:42,660 --> 00:04:47,050
And then here,
we can see more data about other queries.

59
00:04:48,390 --> 00:04:50,870
Now, we can imagine we
have a lot of such data.

60
00:04:52,940 --> 00:04:54,740
Now we can ask the question,

61
00:04:54,740 --> 00:04:58,460
how can we then estimate
the probability of relevance?

62
00:05:00,390 --> 00:05:03,690
So how can we compute this
probability of relevance?

63
00:05:03,690 --> 00:05:06,230
Well, intuitively that just means

64
00:05:06,230 --> 00:05:10,770
if we look at all the entries
where we see this particular d and

65
00:05:10,770 --> 00:05:16,010
this particular q, how likely we'll
see a one on this other column.

66
00:05:16,010 --> 00:05:18,500
So basically that just means that
we can just collect the counts.

67
00:05:19,730 --> 00:05:24,536
We can first count how many
times we have seen q and

68
00:05:24,536 --> 00:05:29,576
d as a pair in this table and
then count how many times

69
00:05:29,576 --> 00:05:34,518
we actually have also seen
1 in the third column.

70
00:05:34,518 --> 00:05:37,227
And then, we just compute the ratio.

71
00:05:39,409 --> 00:05:42,347
So let's take a look at
some specific examples.

72
00:05:42,347 --> 00:05:48,466
Suppose we are trying to compute this
probability for d1, d2 and d3 for q1.

73
00:05:48,466 --> 00:05:52,240
What is the estimated probability?

74
00:05:52,240 --> 00:05:54,760
Now, think about that.

75
00:05:54,760 --> 00:05:58,823
You can pause the video if needed.

76
00:05:58,823 --> 00:06:01,560
Try to take a look at the table.

77
00:06:01,560 --> 00:06:04,606
And try to give your
estimate of the probability.

78
00:06:07,069 --> 00:06:11,802
Have you seen that,
if we are interested in q1 and d1,

79
00:06:11,802 --> 00:06:15,050
we'll be looking at these two pairs?

80
00:06:15,050 --> 00:06:18,020
And in both cases, well,

81
00:06:18,020 --> 00:06:23,190
actually, in one of the cases, the user
has said this is 1, this is relevant.

82
00:06:23,190 --> 00:06:26,282
So R = 1 in only one of the two cases.

83
00:06:26,282 --> 00:06:28,244
In the other case, it's 0.

84
00:06:28,244 --> 00:06:30,846
So that's one out of two.

85
00:06:30,846 --> 00:06:34,525
What about the d1 and the d2?

86
00:06:34,525 --> 00:06:39,127
Well, they are here, d1 and d2, d1 and d2,

87
00:06:39,127 --> 00:06:42,729
in both cases, in this case, R = 1.

88
00:06:42,729 --> 00:06:45,700
So it's a two out of two and
so on and so forth.

89
00:06:45,700 --> 00:06:48,195
So you can see with this approach,

90
00:06:48,195 --> 00:06:52,679
we can actually score these documents for
the query, right?

91
00:06:52,679 --> 00:06:56,625
We now have a score for d1,
d2 and d3 for this query.

92
00:06:56,625 --> 00:07:00,334
And we can simply rank them
based on these probabilities and

93
00:07:00,334 --> 00:07:04,056
so that's the basic idea
probabilistic retrieval model.

94
00:07:04,056 --> 00:07:06,971
And you can see it makes a lot of sense,
in this case,

95
00:07:06,971 --> 00:07:10,036
it's going to rank d2 above
all the other documents.

96
00:07:10,036 --> 00:07:15,992
Because in all the cases,
when you have c and q1 and d2, R = 1.

97
00:07:15,992 --> 00:07:18,314
The user clicked on this document.

98
00:07:18,314 --> 00:07:23,957
So this also should show that
with a lot of click-through data,

99
00:07:23,957 --> 00:07:30,830
a search engine can learn a lot from
the data to improve their search engine.

100
00:07:30,830 --> 00:07:33,580
This is a simple example
that shows that with even

101
00:07:33,580 --> 00:07:38,760
with small amount of entries here we can
already estimate some probabilities.

102
00:07:38,760 --> 00:07:42,160
These probabilities would give us
some sense about which document

103
00:07:42,160 --> 00:07:46,160
might be more relevant or more useful
to a user for typing this query.

104
00:07:47,170 --> 00:07:51,100
Now, of course, the problems that we
don't observe all the queries and

105
00:07:51,100 --> 00:07:54,048
all the documents and
all the relevance values, right?

106
00:07:55,320 --> 00:07:57,890
There would be a lot of unseen documents,
in general,

107
00:07:57,890 --> 00:08:02,880
we have only collected the data from the
documents that we have shown to the users.

108
00:08:02,880 --> 00:08:07,370
And there are even more unseen queries
because you cannot predict what

109
00:08:07,370 --> 00:08:10,060
queries will be typed in by users.

110
00:08:10,060 --> 00:08:15,090
So obviously,
this approach won't work if we apply

111
00:08:15,090 --> 00:08:17,190
it to unseen queries or unseen documents.

112
00:08:18,635 --> 00:08:22,278
Nevertheless, this shows the basic idea
of probabilistic retrieval model and

113
00:08:22,278 --> 00:08:23,646
it makes sense intuitively.

114
00:08:23,646 --> 00:08:28,275
So what do we do in such a case when
we have a lot of unseen documents and

115
00:08:28,275 --> 00:08:29,508
unseen queries?

116
00:08:29,508 --> 00:08:32,818
Well, the solutions that we have
to approximate in some way.

117
00:08:32,818 --> 00:08:37,003
So in this particular case called
a query likelihood retrieval model,

118
00:08:37,003 --> 00:08:40,784
we just approximate this by
another conditional probability.

119
00:08:40,784 --> 00:08:46,682
p(q given d, R=1).

120
00:08:46,682 --> 00:08:51,539
So in the condition part, we assume that
the user likes the document because we

121
00:08:51,539 --> 00:08:54,640
have seen that the user
clicked on this document.

122
00:08:56,190 --> 00:08:58,777
And this part shows that
we're interested in how

123
00:08:58,777 --> 00:09:01,438
likely the user would
actually enter this query.

124
00:09:01,438 --> 00:09:04,653
How likely we will see this
query in the same row.

125
00:09:04,653 --> 00:09:08,880
So note that here, we have made
an interesting assumption here.

126
00:09:08,880 --> 00:09:13,900
Basically, we're going to do, assume that
whether the user types in this query

127
00:09:13,900 --> 00:09:17,970
has something to do with whether
user likes the document.

128
00:09:17,970 --> 00:09:20,740
In other words,
we actually make the following assumption.

129
00:09:22,160 --> 00:09:27,671
And that is a user formulates a query
based on an imaginary relevant document.

130
00:09:27,671 --> 00:09:30,358
Where if you just look at this
as conditional probability,

131
00:09:30,358 --> 00:09:32,629
it's not obvious we
are making this assumption.

132
00:09:32,629 --> 00:09:37,941
So what I really meant is that
to use this new conditional

133
00:09:37,941 --> 00:09:43,367
probability to help us score,
then this new conditional

134
00:09:43,367 --> 00:09:48,794
probability will have to somehow
be able to estimate this

135
00:09:48,794 --> 00:09:54,696
conditional probability without
relying on this big table.

136
00:09:54,696 --> 00:09:59,306
Otherwise we would be having
similar problems as before, and

137
00:09:59,306 --> 00:10:04,537
by making this assumption,
we have some way to bypass this big table,

138
00:10:04,537 --> 00:10:09,252
and try to just model how the user
formulates the query, okay?

139
00:10:09,252 --> 00:10:13,639
So this is how you can
simplify the general model so

140
00:10:13,639 --> 00:10:18,570
that we can derive a specific
relevant function later.

141
00:10:18,570 --> 00:10:22,020
So let's look at how this model work for
our example.

142
00:10:22,020 --> 00:10:23,300
And basically,

143
00:10:23,300 --> 00:10:27,420
what we are going to do in this case
is to ask the following question.

144
00:10:27,420 --> 00:10:30,760
Which of these documents is most
likely the imaginary relevant

145
00:10:30,760 --> 00:10:34,300
document in the user's mind when
the user formulates this query?

146
00:10:34,300 --> 00:10:38,488
So we ask this question and we quantify
the probability and this probability is

147
00:10:38,488 --> 00:10:43,443
a conditional probability of observing
this query if a particular document is in

148
00:10:43,443 --> 00:10:47,245
fact the imaginary relevant
document in the user's mind.

149
00:10:47,245 --> 00:10:51,885
Here you can see we've computed all
these query likelihood probabilities.

150
00:10:51,885 --> 00:10:55,340
The likelihood of queries
given each document.

151
00:10:55,340 --> 00:10:56,880
Once we have these values,

152
00:10:56,880 --> 00:11:00,370
we can then rank these documents
based on these values.

153
00:11:00,370 --> 00:11:05,420
So to summarize, the general idea
of modern relevance in the proper

154
00:11:05,420 --> 00:11:11,740
risk model is to assume the we introduce
a binary random variable R, here.

155
00:11:11,740 --> 00:11:12,690
And then,

156
00:11:12,690 --> 00:11:16,740
let the scoring function be defined
based on this conditional probability.

157
00:11:16,740 --> 00:11:20,980
We also talked about approximating
this by using the query likelihood.

158
00:11:22,450 --> 00:11:27,065
And in this case we have a ranking
function that's basically

159
00:11:27,065 --> 00:11:31,385
based on the probability of
a query given the document.

160
00:11:31,385 --> 00:11:36,165
And this probability should be interpreted
as the probability that a user who

161
00:11:36,165 --> 00:11:39,236
likes document d, would pose query q.

162
00:11:40,265 --> 00:11:44,645
Now, the question of course is, how do
we compute this conditional probability?

163
00:11:44,645 --> 00:11:49,500
At this in general has to do with how
you compute the probability of text,

164
00:11:49,500 --> 00:11:51,980
because q is a text.

165
00:11:51,980 --> 00:11:56,560
And this has to do with a model
called a Language Model.

166
00:11:56,560 --> 00:12:00,580
And these kind of models
are proposed to model text.

167
00:12:02,190 --> 00:12:07,440
So more specifically, we will be
very interested in the following

168
00:12:07,440 --> 00:12:12,050
conditional probability
as is shown in this here.

169
00:12:12,050 --> 00:12:18,463
If the user liked this document,
how likely the user would pose this query.

170
00:12:18,463 --> 00:12:21,884
And in the next lecture we're going to do,

171
00:12:21,884 --> 00:12:27,016
giving introduction to language
models that we can see how we

172
00:12:27,016 --> 00:12:32,063
can model text that was a probable
risk model, in general.

173
00:12:32,063 --> 00:12:42,063
[MUSIC]