1
00:00:00,012 --> 00:00:03,532
[SOUND]

2
00:00:07,767 --> 00:00:10,058
This lecture is about query likelihood,

3
00:00:10,058 --> 00:00:11,960
probabilistic retrieval model.

4
00:00:14,040 --> 00:00:15,310
In this lecture,

5
00:00:15,310 --> 00:00:19,190
we continue the discussion of
probabilistic retrieval model.

6
00:00:19,190 --> 00:00:22,830
In particular, we're going to talk about
the query light holder retrieval function.

7
00:00:25,870 --> 00:00:31,073
In the query light holder retrieval model,
our idea is model.

8
00:00:31,073 --> 00:00:35,420
How like their user who likes a document
with pose a particular query?

9
00:00:36,990 --> 00:00:41,462
So in this case,
you can imagine if a user likes this

10
00:00:41,462 --> 00:00:46,663
particular document about
a presidential campaign news.

11
00:00:46,663 --> 00:00:50,410
Now we assume,
the user would use this a document as

12
00:00:50,410 --> 00:00:54,780
a basis to impose a query to try and
retrieve this document.

13
00:00:57,340 --> 00:01:03,840
So again, imagine use a process
that works as follows.

14
00:01:03,840 --> 00:01:06,940
Where we assume that
the query is generated by

15
00:01:06,940 --> 00:01:08,640
assembling words from the document.

16
00:01:10,560 --> 00:01:15,880
So for example, a user might
pick a word like presidential,

17
00:01:15,880 --> 00:01:19,390
from this document and
then use this as a query word.

18
00:01:20,600 --> 00:01:24,590
And then the user would pick
another word like campaign, and

19
00:01:24,590 --> 00:01:25,910
that would be the second query word.

20
00:01:27,420 --> 00:01:32,400
Now this of course is an assumption
that we have made about

21
00:01:32,400 --> 00:01:35,008
how a user would pose a query.

22
00:01:35,008 --> 00:01:39,788
Whether a user actually followed this
process may be a different question, but

23
00:01:39,788 --> 00:01:45,230
this assumption has allowed us to formerly
characterize this conditional probability.

24
00:01:46,390 --> 00:01:50,930
And this allows us to also not rely on
the big table that I showed you earlier

25
00:01:52,580 --> 00:01:55,750
to use empirical data to
estimate this probability.

26
00:01:56,870 --> 00:02:00,820
And this is why we can use this
idea then to further derive

27
00:02:00,820 --> 00:02:03,569
retrieval function that we can
implement with the program language.

28
00:02:04,900 --> 00:02:08,991
So as you see the assumption
that we made here is each query

29
00:02:08,991 --> 00:02:11,558
word is independent of the sample.

30
00:02:11,558 --> 00:02:17,880
And also each word is basically
obtained from the document.

31
00:02:20,910 --> 00:02:24,540
So now let's see how this works exactly.

32
00:02:24,540 --> 00:02:28,550
Well, since we are completing
a query likelihood

33
00:02:29,730 --> 00:02:34,444
then the probability here is just
the probability of this particular query,

34
00:02:34,444 --> 00:02:37,210
which is a sequence of words.

35
00:02:37,210 --> 00:02:42,140
And we make the assumption that each
word is generated independently.

36
00:02:42,140 --> 00:02:46,670
So as a result, the probability
of the query is just a product

37
00:02:46,670 --> 00:02:48,920
of the probability of each query word.

38
00:02:50,100 --> 00:02:52,660
Now how do we compute
the probability of each query word?

39
00:02:52,660 --> 00:02:56,740
Well, based on the assumption that a word

40
00:02:56,740 --> 00:03:01,360
is picked from the document
that the user has in mind.

41
00:03:01,360 --> 00:03:05,680
Now we know the probability of each word
is just the relative frequency of each

42
00:03:05,680 --> 00:03:08,120
word in the document.

43
00:03:08,120 --> 00:03:13,780
So for example, the probability of
presidential given the document.

44
00:03:13,780 --> 00:03:17,520
Would be just the count
of presidential document

45
00:03:17,520 --> 00:03:23,060
divided by the total number of words
in the document or document s.

46
00:03:23,060 --> 00:03:28,940
So with these assumptions we now have
actually a simple formula for retrieval.

47
00:03:28,940 --> 00:03:30,970
We can use this to rank our documents.

48
00:03:32,650 --> 00:03:34,200
So does this model work?

49
00:03:34,200 --> 00:03:35,260
Let's take a look.

50
00:03:35,260 --> 00:03:38,670
Here are some example documents
that you have seen before.

51
00:03:38,670 --> 00:03:42,210
Suppose now the query is
presidential campaign and

52
00:03:42,210 --> 00:03:44,880
we see the formula here on the top.

53
00:03:45,900 --> 00:03:47,490
So how do we score this document?

54
00:03:47,490 --> 00:03:48,790
Well, it's very simple.

55
00:03:48,790 --> 00:03:51,370
We just count how many times do
we have seen presidential or

56
00:03:51,370 --> 00:03:54,380
how many times do we have seen campaigns,
etc.

57
00:03:54,380 --> 00:03:57,458
And we see here 44, and
we've seen presidential twice.

58
00:03:57,458 --> 00:04:02,297
So that's 2 over the length of
document 4 multiplied by 1 over

59
00:04:02,297 --> 00:04:07,710
the length of document 4 for
the probability of campaign.

60
00:04:07,710 --> 00:04:11,146
And similarly, we can get probabilities
for the other two documents.

61
00:04:13,189 --> 00:04:17,505
Now if you look at these numbers or
these formulas for

62
00:04:17,505 --> 00:04:22,030
scoring all these documents,
it seems to make sense.

63
00:04:22,030 --> 00:04:28,436
Because if we assume d3 and
d4 have about the same length,

64
00:04:28,436 --> 00:04:35,628
then looks like a nominal rank d4
above d3 and which is above d2.

65
00:04:35,628 --> 00:04:40,819
And as we would expect,
looks like it did captures

66
00:04:40,819 --> 00:04:45,916
a TF query state, and so
this seems to work well.

67
00:04:45,916 --> 00:04:50,096
However, if we try a different
query like this one,

68
00:04:50,096 --> 00:04:54,854
presidential campaign update
then we might see a problem.

69
00:04:54,854 --> 00:04:56,608
Well what problem?

70
00:04:56,608 --> 00:04:58,930
Well think about the update.

71
00:04:58,930 --> 00:05:02,500
Now none of these documents
has mentioned update.

72
00:05:02,500 --> 00:05:08,420
So according to our assumption that a user
would pick a word from a document to

73
00:05:08,420 --> 00:05:15,003
generate a query, then the probability of
obtaining the word update would be what?

74
00:05:15,003 --> 00:05:16,070
Would be 0.

75
00:05:17,230 --> 00:05:21,380
So that causes a problem,
because it would cause all these documents

76
00:05:21,380 --> 00:05:23,710
to have zero probability
of generating this query.

77
00:05:25,330 --> 00:05:31,127
Now why it's fine to have zero probability
for d2, which is non-relevant?

78
00:05:31,127 --> 00:05:33,902
It's not okay to have 0 for d3 and

79
00:05:33,902 --> 00:05:38,600
d4 because now we no longer
can distinguish them.

80
00:05:38,600 --> 00:05:39,135
What's worse?

81
00:05:39,135 --> 00:05:41,735
We can't even distinguish them from d2.

82
00:05:41,735 --> 00:05:45,700
So that's obviously not desirable.

83
00:05:45,700 --> 00:05:48,630
Now when a [INAUDIBLE] has such result,

84
00:05:48,630 --> 00:05:50,960
we should think about what
has caused this problem?

85
00:05:52,530 --> 00:05:56,773
So we have to examine what
assumptions have been made,

86
00:05:56,773 --> 00:05:59,644
as we derive this ranking function.

87
00:05:59,644 --> 00:06:03,285
Now is you examine those assumptions
carefully you will realize,

88
00:06:03,285 --> 00:06:04,983
what has caused this problem?

89
00:06:04,983 --> 00:06:09,080
So take a moment to think about it.

90
00:06:09,080 --> 00:06:17,179
What do you think is the reason why update
has zero probability and how do we fix it?

91
00:06:17,179 --> 00:06:22,092
So if you think about this from the moment
you realize that that's because we

92
00:06:22,092 --> 00:06:25,317
have made an assumption
that every query word must

93
00:06:25,317 --> 00:06:29,220
be drawn from the document
in the user's mind.

94
00:06:29,220 --> 00:06:33,982
So in order to fix this, we have to
assume that the user could have drawn

95
00:06:33,982 --> 00:06:36,912
a word not necessarily from the document.

96
00:06:36,912 --> 00:06:38,930
So that's the improved model.

97
00:06:38,930 --> 00:06:40,912
An improvement here is to say that,

98
00:06:40,912 --> 00:06:43,687
well instead of drawing
a word from the document,

99
00:06:43,687 --> 00:06:48,064
let's imagine that the user would actually
draw a word from a document model.

100
00:06:48,064 --> 00:06:50,107
And so I show a model here.

101
00:06:50,107 --> 00:06:54,479
And we assume that this document is
generated using this unigram language

102
00:06:54,479 --> 00:06:55,920
model.

103
00:06:55,920 --> 00:07:01,297
Now, this model doesn't necessarily assign
zero probability for update in fact,

104
00:07:01,297 --> 00:07:05,853
we can assume this model does not
assign zero probability for any word.

105
00:07:05,853 --> 00:07:09,621
Now if we're thinking this way then
the generation process is a little bit

106
00:07:09,621 --> 00:07:10,700
different.

107
00:07:10,700 --> 00:07:14,940
Now the user has this model in mind
instead of this particular document.

108
00:07:14,940 --> 00:07:18,669
Although the model has to be
estimated based on the document.

109
00:07:18,669 --> 00:07:22,960
So the user can again generate
the query using a singular process.

110
00:07:22,960 --> 00:07:27,680
Namely, pick a word for example,
presidential and another word campaign.

111
00:07:29,020 --> 00:07:32,390
Now the difference is that this time
we can also pick a word like update,

112
00:07:32,390 --> 00:07:34,930
even though update doesn't
occur in the document

113
00:07:34,930 --> 00:07:38,050
to potentially generate
a query word like update.

114
00:07:38,050 --> 00:07:43,840
So that a query was updated
1 times 0 probabilities.

115
00:07:43,840 --> 00:07:45,720
So this would fix our problem.

116
00:07:45,720 --> 00:07:50,140
And it's also reasonable because when our
thinking of what the user is looking for

117
00:07:50,140 --> 00:07:55,160
in a more general way, that is unique
language model instead of fixed document.

118
00:07:55,160 --> 00:07:57,830
So how do we compute
this query likelihood?

119
00:07:57,830 --> 00:08:01,000
If we make this sum wide
involved two steps.

120
00:08:01,000 --> 00:08:07,390
The first one is compute this model, and
we call it document language model here.

121
00:08:07,390 --> 00:08:15,070
For example, I've shown two pulse models
here, it's major based on two documents.

122
00:08:15,070 --> 00:08:19,803
And then given a query like a data mining
algorithms the thinking is that we'll

123
00:08:19,803 --> 00:08:22,467
just compute the likelihood of this query.

124
00:08:22,467 --> 00:08:26,574
And by making independence
assumptions we could then have this

125
00:08:26,574 --> 00:08:30,766
probability as a product of
the probability of each query word.

126
00:08:30,766 --> 00:08:34,798
We do this for both documents, and
then we can score these two documents and

127
00:08:34,798 --> 00:08:35,700
then rank them.

128
00:08:37,160 --> 00:08:41,310
So that's the basic idea of this
query likelihood retrieval function.

129
00:08:41,310 --> 00:08:47,890
So more generally this ranking function
would look like in the following.

130
00:08:47,890 --> 00:08:51,800
Here we assume that the query has n words,

131
00:08:51,800 --> 00:08:56,540
w1 through wn, and
then the scoring function.

132
00:08:56,540 --> 00:09:01,500
The ranking function is the probability
that we observe this query,

133
00:09:01,500 --> 00:09:06,080
given that the user is
thinking of this document.

134
00:09:06,080 --> 00:09:11,970
And this is assume it will be product of
probabilities of all individual words.

135
00:09:11,970 --> 00:09:15,360
This is based on independent assumption.

136
00:09:15,360 --> 00:09:20,256
Now we actually often score
the document before this query by

137
00:09:20,256 --> 00:09:25,250
using log of the query likelihood
as shown on the second line.

138
00:09:26,710 --> 00:09:30,220
Now we do this to avoid

139
00:09:30,220 --> 00:09:35,830
having a lot of small probabilities,
mean multiply together.

140
00:09:35,830 --> 00:09:41,060
And this could cause under flow and we
might loose the precision by transforming

141
00:09:41,060 --> 00:09:44,100
the value in our algorithm function.

142
00:09:44,100 --> 00:09:51,079
We maintain the order of these documents
yet we can avoid the under flow problem.

143
00:09:51,079 --> 00:09:54,935
And so if we take longer than
transformation of course,

144
00:09:54,935 --> 00:09:59,920
the product would become a sum
as you on the second line here.

145
00:09:59,920 --> 00:10:03,620
So the sum of all the query
words inside of the sum

146
00:10:03,620 --> 00:10:07,670
that is one of the probability of
this word given by the document.

147
00:10:09,360 --> 00:10:13,020
And then we can further rewrite
the sum to a different form.

148
00:10:14,310 --> 00:10:19,960
So in the first sum here, in this sum,

149
00:10:21,910 --> 00:10:28,800
we have it over all the query words and
query word.

150
00:10:28,800 --> 00:10:33,030
And in this sum we have a sum
of all the possible words.

151
00:10:33,030 --> 00:10:37,050
But we put a counter here
of each word in the query.

152
00:10:37,050 --> 00:10:39,780
Essentially we are only considering
the words in the query,

153
00:10:39,780 --> 00:10:43,570
because if a word is not in the query,
the count will be 0.

154
00:10:43,570 --> 00:10:46,820
So we're still considering
only these n words.

155
00:10:46,820 --> 00:10:49,760
But we're using a different form as
if we were going to take a sample of

156
00:10:49,760 --> 00:10:51,570
all the words in the vocabulary.

157
00:10:52,960 --> 00:10:56,435
And of course, a word might occur
multiple times in the query.

158
00:10:56,435 --> 00:10:58,631
That's why we have a count here.

159
00:11:00,407 --> 00:11:04,168
And then this part is log of
the probability of the word,

160
00:11:04,168 --> 00:11:06,815
given by the document language model.

161
00:11:08,647 --> 00:11:11,497
So you can see in this retrieval function,

162
00:11:11,497 --> 00:11:13,547
we actually know the count
of the word in the query.

163
00:11:13,547 --> 00:11:16,507
So the only thing that we don't know
is this document language model.

164
00:11:17,817 --> 00:11:21,310
Therefore, we have converted
the retrieval problem

165
00:11:21,310 --> 00:11:24,510
include the problem of estimating
this document language model.

166
00:11:25,920 --> 00:11:30,370
So that we can compute the probability of
each query word given by this document.

167
00:11:32,260 --> 00:11:36,630
And different estimation methods would
lead to different ranking functions.

168
00:11:36,630 --> 00:11:40,980
This is just like a different way to
place document in the vector space

169
00:11:40,980 --> 00:11:45,485
which leads to a different ranking
function in the vector space model.

170
00:11:45,485 --> 00:11:49,353
Here different ways to
estimate will lead to

171
00:11:49,353 --> 00:11:54,065
a different ranking function for
query likelihood.

172
00:11:54,065 --> 00:12:04,065
[MUSIC]