1
00:00:00,883 --> 00:00:05,127
[MUSIC]

2
00:00:07,433 --> 00:00:12,376
This lecture is about how to evaluate
the text retrieval system when we have

3
00:00:12,376 --> 00:00:15,560
multiple levels of judgements.

4
00:00:15,560 --> 00:00:19,994
In this lecture, we will continue
the discussion of evaluation.

5
00:00:19,994 --> 00:00:23,410
We're going to look at how to
evaluate a text retrieval system,

6
00:00:23,410 --> 00:00:26,150
when we have multiple
levels of judgements.

7
00:00:27,760 --> 00:00:31,180
So far we have talked about
the binary judgements,

8
00:00:31,180 --> 00:00:34,169
that means a document is judged as
being relevant or not relevant.

9
00:00:35,270 --> 00:00:40,310
But earlier, we also talk about
the relevance as a medal of degrees.

10
00:00:40,310 --> 00:00:45,580
So we often can distinguish
very high relevant documents,

11
00:00:45,580 --> 00:00:50,230
those are very useful documents,
from moderately relevant documents.

12
00:00:50,230 --> 00:00:53,000
They are okay, they are useful perhaps.

13
00:00:53,000 --> 00:00:56,170
And further from now, we're adding
the documents, those are not useful.

14
00:00:57,450 --> 00:01:01,490
So imagine you can have ratings for
these pages.

15
00:01:01,490 --> 00:01:05,390
Then, you would have
multiple levels of ratings.

16
00:01:05,390 --> 00:01:10,803
For example, here I show example of three
levels, 3 for relevant, sorry 3 for

17
00:01:10,803 --> 00:01:15,780
very relevant, 2 for marginally relevant,
and 1 for non-relevant.

18
00:01:15,780 --> 00:01:18,990
Now, how do we evaluate the search
engine system using these judgements?

19
00:01:18,990 --> 00:01:23,330
Obvious that the map doesn't work, average
of precision doesn't work, precision, and

20
00:01:23,330 --> 00:01:28,190
recall doesn't work,
because they rely on binary judgements.

21
00:01:28,190 --> 00:01:33,510
So let's look at some top ranked
results when using these judgements.

22
00:01:33,510 --> 00:01:38,518
Imagine the user would be mostly
care about the top ten results here.

23
00:01:43,122 --> 00:01:48,165
And we marked the rating levels,
or relevance levels,

24
00:01:48,165 --> 00:01:54,620
for these documents as shown here,
3, 2, 1, 1, 3, etcetera.

25
00:01:54,620 --> 00:01:57,122
And we call these gain.

26
00:01:57,122 --> 00:02:02,345
And the reason why we call it
the gain is because the measure

27
00:02:02,345 --> 00:02:08,860
that we are infusing is called the NDCG
normalized or accumulated gain.

28
00:02:10,090 --> 00:02:14,900
So this gain, basically,
can measure how much a gain of random

29
00:02:14,900 --> 00:02:19,790
information a user can obtain by
looking at each document, right?

30
00:02:19,790 --> 00:02:24,120
So looking at the first document,
the user can gain 3 points.

31
00:02:24,120 --> 00:02:28,110
Looking at the non-relevant document
user would only gain 1 point.

32
00:02:29,510 --> 00:02:32,703
Looking at the moderator or
marginally relevant,

33
00:02:32,703 --> 00:02:35,910
document the user would get 2 points,
etcetera.

34
00:02:35,910 --> 00:02:40,560
So, this gain to each of the measures is
a utility of the document from a user's

35
00:02:40,560 --> 00:02:41,890
perspective.

36
00:02:41,890 --> 00:02:46,140
Of course, if we assume the user
stops at the 10 documents and

37
00:02:46,140 --> 00:02:51,060
we're looking at the cutoff at 10,
we can look at the total gain of the user.

38
00:02:51,060 --> 00:02:51,774
And what's that?

39
00:02:51,774 --> 00:02:55,825
Well, that's simply the sum of these,
and we call it the Cumulative Gain.

40
00:02:55,825 --> 00:02:59,275
So if the user stops after the position 1,
that's just a 3.

41
00:02:59,275 --> 00:03:03,163
If the user looks at another document,
that's a 3+2.

42
00:03:03,163 --> 00:03:08,221
If the user looks at the more documents,
then the cumulative gain is more.

43
00:03:08,221 --> 00:03:13,200
Of course this is at the cost of
spending more time to examine the list.

44
00:03:13,200 --> 00:03:16,390
So cumulative gain gives
us some idea about how

45
00:03:16,390 --> 00:03:21,368
much total gain the user would have if
the user examines all these documents.

46
00:03:21,368 --> 00:03:28,140
Now, in NDCG, we also have another letter
here, D, discounted cumulative gain.

47
00:03:29,170 --> 00:03:32,060
So, why do we want to do discounting?

48
00:03:32,060 --> 00:03:35,685
Well, if you look at this cumulative gain,
there is one deficiency,

49
00:03:35,685 --> 00:03:41,975
which is it did not consider the rank
position of these documents.

50
00:03:41,975 --> 00:03:46,115
So for example, looking at this sum here,

51
00:03:46,115 --> 00:03:51,485
and we only know there is 1
highly relevant document,

52
00:03:51,485 --> 00:03:54,945
1 marginally relevant document,
2 non-relevant documents.

53
00:03:54,945 --> 00:03:57,300
We don't really care
where they are ranked.

54
00:03:57,300 --> 00:04:02,110
Ideally, we want these two to be ranked
on the top which is the case here.

55
00:04:03,120 --> 00:04:06,420
But how can we capture that intuition?

56
00:04:06,420 --> 00:04:13,209
Well we have to say, well this is 3 here
is not as good as this 3 on the top.

57
00:04:13,209 --> 00:04:18,114
And that means the contribution
of the gain from different

58
00:04:18,114 --> 00:04:22,750
positions has to be
weighted by their position.

59
00:04:22,750 --> 00:04:24,666
And this is the idea of discounting,
basically.

60
00:04:24,666 --> 00:04:29,530
So we're going to to say, well, the first
one does not need to be discounted

61
00:04:29,530 --> 00:04:33,910
because the user can be assumed
that will always see this document.

62
00:04:33,910 --> 00:04:38,030
But the second one,
this one will be discounted a little bit

63
00:04:38,030 --> 00:04:42,370
because there's a small possibility
that the user wouldn't notice it.

64
00:04:42,370 --> 00:04:48,690
So we divide this gain by
a weight based on the position.

65
00:04:48,690 --> 00:04:52,640
So log of 2,
2 is the rank position of this document.

66
00:04:52,640 --> 00:04:57,080
And when we go to the third position,
we discounted even more,

67
00:04:57,080 --> 00:05:01,270
because the normalizer is log of 3,
and so on and so forth.

68
00:05:01,270 --> 00:05:06,690
So when we take such a sum that a lower
ranked document would not contribute

69
00:05:06,690 --> 00:05:10,000
that much as a highly ranked document.

70
00:05:10,000 --> 00:05:15,120
So that means if you, for example,
switch the position of this, let's say

71
00:05:15,120 --> 00:05:20,726
this position, and this one, and then
you would get more discount if you put,

72
00:05:20,726 --> 00:05:27,050
for example very relevant
document here as opposed to here.

73
00:05:27,050 --> 00:05:31,290
Imagine if you put the 3 here,
then it would have to be discounted.

74
00:05:31,290 --> 00:05:34,635
So it's not as good as if
you we would put the 3 here.

75
00:05:34,635 --> 00:05:36,650
So this is the idea of discounting.

76
00:05:37,900 --> 00:05:43,210
Okay, so now at this point that we have
got a discounted cumulative gain for

77
00:05:43,210 --> 00:05:50,000
measuring the utility of this ranked
list with multiple levels of judgements.

78
00:05:51,480 --> 00:05:53,125
So are we happy with this?

79
00:05:53,125 --> 00:05:55,680
Well, we can use this to rank systems.

80
00:05:55,680 --> 00:05:58,510
Now, we still need to do a little bit more

81
00:05:58,510 --> 00:06:03,272
in order to make this measure
comparable across different topics.

82
00:06:03,272 --> 00:06:10,580
And this is the last step, and by the way,
here we just show the DCG at 10,

83
00:06:10,580 --> 00:06:16,820
so this is the total sum of DCG,
all these 10 documents.

84
00:06:16,820 --> 00:06:20,880
So the last step is called N,
normalization.

85
00:06:20,880 --> 00:06:25,240
And if we do that,
then we'll get the normalized DCG.

86
00:06:25,240 --> 00:06:26,463
So how do we do that?

87
00:06:26,463 --> 00:06:31,241
Well, the idea here is we're
going to normalize DCG by

88
00:06:31,241 --> 00:06:35,280
the ideal DCG at the same cutoff.

89
00:06:35,280 --> 00:06:37,130
What is the ideal DCG?

90
00:06:37,130 --> 00:06:40,830
Well, this is the DCG of an ideal ranking.

91
00:06:40,830 --> 00:06:47,690
So imagine if we have 9 documents in
the whole collection rated 3 here.

92
00:06:47,690 --> 00:06:52,840
And that means in total we
have 9 documents rated 3.

93
00:06:53,840 --> 00:07:00,640
Then our ideal rank lister would have put
all these 9 documents on the very top.

94
00:07:00,640 --> 00:07:05,730
So all these would have to be 3 and
then this would be followed by a 2 here.

95
00:07:05,730 --> 00:07:10,040
Because that's the best we could
do after we have run out of the 3.

96
00:07:10,040 --> 00:07:11,800
But all these positions would be 3.

97
00:07:11,800 --> 00:07:13,938
Right?

98
00:07:13,938 --> 00:07:16,090
So this would our ideal ranked list.

99
00:07:18,070 --> 00:07:21,700
And then we had computed the DCG for
this ideal rank list.

100
00:07:23,250 --> 00:07:27,062
So this would be given by this
formula that you see here.

101
00:07:27,062 --> 00:07:35,723
And so this ideal DCG would then
be used as the normalizer DCG.

102
00:07:35,723 --> 00:07:36,845
So here.

103
00:07:36,845 --> 00:07:40,040
And this idea of DCG would
be used as a normalizer.

104
00:07:40,040 --> 00:07:43,726
So you can imagine now,
normalization essentially is to

105
00:07:43,726 --> 00:07:49,590
compare the actual DCG with the best DCG
you can possibly get for this topic.

106
00:07:49,590 --> 00:07:51,146
Now why do we want to do this?

107
00:07:51,146 --> 00:07:56,590
Well, by doing this we'll map the DCG
values into a range of 0 through 1.

108
00:07:57,900 --> 00:08:01,650
So the best value, or the highest value,
for every query would be 1.

109
00:08:01,650 --> 00:08:07,500
That's when your rank list is,
in fact, the ideal list but

110
00:08:07,500 --> 00:08:12,260
otherwise, in general,
you will be lower than one.

111
00:08:13,405 --> 00:08:14,954
Now, what if we don't do that?

112
00:08:14,954 --> 00:08:19,737
Well, you can see, this transformation,
or this normalization,

113
00:08:19,737 --> 00:08:24,108
doesn't really affect the relative
comparison of systems for

114
00:08:24,108 --> 00:08:29,053
just one topic, because this ideal
DCG is the same for all the systems,

115
00:08:29,053 --> 00:08:33,834
so the ranking of systems based on
only DCG would be exactly the same as

116
00:08:33,834 --> 00:08:36,986
if you rank them based
on the normalized DCG.

117
00:08:36,986 --> 00:08:40,760
The difference however is
when we have multiple topics.

118
00:08:40,760 --> 00:08:42,894
Because if we don't do normalization,

119
00:08:42,894 --> 00:08:45,730
different topics will have
different scales of DCG.

120
00:08:46,740 --> 00:08:51,951
For a topic like this one,
we have 9 highly relevant documents,

121
00:08:51,951 --> 00:08:56,593
the DCG can get really high,
but imagine in another case,

122
00:08:56,593 --> 00:09:02,794
there are only two very relevant documents
in total in the whole collection.

123
00:09:02,794 --> 00:09:06,124
Then the highest DCG that
any system could achieve for

124
00:09:06,124 --> 00:09:09,210
such a topic would not be very high.

125
00:09:09,210 --> 00:09:15,555
So again, we face the problem of
different scales of DCG values.

126
00:09:15,555 --> 00:09:17,028
When we take an average,

127
00:09:17,028 --> 00:09:20,826
we don't want the average to be
dominated by those high values.

128
00:09:20,826 --> 00:09:23,360
Those are, again, easy queries.

129
00:09:23,360 --> 00:09:27,220
So, by doing the normalization,
we can have avoided the problem,

130
00:09:27,220 --> 00:09:31,690
making all the queries contribute
to equal to the average.

131
00:09:31,690 --> 00:09:34,882
So, this is a idea of NDCG, it's used for

132
00:09:34,882 --> 00:09:40,470
measuring a rank list based on multiple
level of relevance judgements.

133
00:09:42,830 --> 00:09:47,951
In a more general way this
is basically a measure

134
00:09:47,951 --> 00:09:55,900
that can be applied to any ranked task
with multiple level of judgements.

135
00:09:55,900 --> 00:10:01,111
And the scale of the judgements
can be multiple, can be more than

136
00:10:01,111 --> 00:10:07,094
binary not only more than binary they
can be much multiple levels like 1,

137
00:10:07,094 --> 00:10:11,365
0, 5 or
even more depending on your application.

138
00:10:11,365 --> 00:10:15,631
And the main idea of this measure,
just to summarize,

139
00:10:15,631 --> 00:10:19,920
is to measure the total utility
of the top k documents.

140
00:10:19,920 --> 00:10:24,120
So you always choose a cutoff and
then you measure the total utility.

141
00:10:24,120 --> 00:10:28,700
And it would discount the contribution
from a lowly ranked document.

142
00:10:28,700 --> 00:10:31,811
And then finally,

143
00:10:31,811 --> 00:10:37,645
it would do normalization to ensure

144
00:10:37,645 --> 00:10:43,093
comparability across queries.

145
00:10:43,093 --> 00:10:48,319
[MUSIC]