<meta charset="utf-8"/>
<co-content>
 <h1 level="1">
  Week 8 Overview
 </h1>
 <p>
  During this week's lessons, you will learn more about word association mining with a particular focus on mining the other basic form of word association (i.e., syntagmatic relations), and start learning topic analysis with a focus on techniques for mining one topic from text.
 </p>
 <h2 level="2">
  Time
 </h2>
 <p>
  This module should take
  <strong>
   approximately 4 hours
  </strong>
  of dedicated time to complete, with its videos and assignments.
 </p>
 <h2 level="2">
  Activities
 </h2>
 <p>
  The activities for this module are listed below (with required assignments in bold):
 </p>
 <table columns="2" rows="4">
  <tr>
   <td>
    <p>
     <strong>
      Activity
     </strong>
    </p>
   </td>
   <td>
    <p>
     <strong>
      Estimated Time Required
     </strong>
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     Week 8 Video Lectures
    </p>
   </td>
   <td>
    <p>
     2 hours
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     <strong>
      Week 8
     </strong>
     <strong>
      Graded
     </strong>
     <strong>
      Quiz
     </strong>
    </p>
   </td>
   <td>
    <p>
     1 hour
    </p>
   </td>
  </tr>
  <tr>
   <td>
    <p>
     Technology Review (due Week 14)
    </p>
   </td>
   <td>
    <p>
     1 hour
    </p>
   </td>
  </tr>
 </table>
 <h2 level="2">
  Goals and Objectives
 </h2>
 <p>
  After you actively engage in the learning experiences in this module, you should be able to:
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    Explain some basic concepts in natural language processing and text information access.
   </p>
  </li>
  <li>
   <p>
    Explain why text retrieval is often defined as a ranking problem.
   </p>
  </li>
  <li>
   <p>
    Explain the basic idea of the vector space retrieval model and how to instantiate it with the simplest bit-vector representation.
   </p>
  </li>
 </ul>
 <h2 level="2">
  Guiding Questions
 </h2>
 <p>
  Develop your answers to the following guiding questions while watching the video lectures throughout the week.
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    What is entropy? For what kind of random variables does the entropy function reach its minimum and maximum, respectively?
   </p>
  </li>
  <li>
   <p>
    What is conditional entropy?
   </p>
  </li>
  <li>
   <p>
    What is the relation between conditional entropy H(X|Y) and entropy H(X)? Which is larger?
   </p>
  </li>
  <li>
   <p>
    How can conditional entropy be used for discovering syntagmatic relations?
   </p>
  </li>
  <li>
   <p>
    What is mutual information I(X;Y)? How is it related to entropy H(X) and conditional entropy H(X|Y)?
   </p>
  </li>
  <li>
   <p>
    What’s the minimum value of I(X;Y)? Is it symmetric?
   </p>
  </li>
  <li>
   <p>
    For what kind of X and Y, does mutual information I(X;Y) reach its minimum? For a given X, for what Y does I(X;Y) reach its maximum?
   </p>
  </li>
  <li>
   <p>
    Why is mutual information sometimes more useful for discovering syntagmatic relations than conditional entropy?
   </p>
  </li>
  <li>
   <p>
    What is a topic?
   </p>
  </li>
  <li>
   <p>
    How can we define the task of topic mining and analysis computationally? What’s the input? What’s the output?
   </p>
  </li>
  <li>
   <p>
    How can we heuristically solve the problem of topic mining and analysis by treating a term as a topic? What are the main problems of such an approach?
   </p>
  </li>
  <li>
   <p>
    What are the benefits of representing a topic by a word distribution?
   </p>
  </li>
  <li>
   <p>
    What is a statistical language model? What is a unigram language model? How can we compute the probability of a sequence of words given a unigram language model?
   </p>
  </li>
  <li>
   <p>
    What is Maximum Likelihood estimate of a unigram language model given a text article?
   </p>
  </li>
  <li>
   <p>
    What is the basic idea of Bayesian estimation? What is a prior distribution? What is a posterior distribution? How are they related with each other? What is Bayes rule?
   </p>
  </li>
 </ul>
 <h2 level="2">
  Additional Readings and Resources
 </h2>
 <p>
  The following readings are optional:
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    C. Zhai and S. Massung.
    <em>
     Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining
    </em>
    , ACM and Morgan &amp; Claypool Publishers, 2016. Chapters 13, 17.
   </p>
  </li>
 </ul>
 <h2 level="2">
  Key Phrases and Concepts
 </h2>
 <p>
  Keep your eyes open for the following key terms or phrases as you complete the readings and interact with the lectures. These topics will help you better understand the content in this module.
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    Entropy
   </p>
  </li>
  <li>
   <p>
    Conditional entropy
   </p>
  </li>
  <li>
   <p>
    Mutual information
   </p>
  </li>
  <li>
   <p>
    Topic and coverage of topic
   </p>
  </li>
  <li>
   <p>
    Language model
   </p>
  </li>
  <li>
   <p>
    Generative model
   </p>
  </li>
  <li>
   <p>
    Unigram language model
   </p>
  </li>
  <li>
   <p>
    Word distribution
   </p>
  </li>
  <li>
   <p>
    Background language model
   </p>
  </li>
  <li>
   <p>
    Parameters of a probabilistic model
   </p>
  </li>
  <li>
   <p>
    Likelihood
   </p>
  </li>
  <li>
   <p>
    Bayes rule
   </p>
  </li>
  <li>
   <p>
    Maximum likelihood estimation
   </p>
  </li>
  <li>
   <p>
    Prior and posterior distributions
   </p>
  </li>
  <li>
   <p>
    Bayesian estimation &amp; inference
   </p>
  </li>
  <li>
   <p>
    Maximum a posteriori (MAP) estimate
   </p>
  </li>
  <li>
   <p>
    Prior model
   </p>
  </li>
  <li>
   <p>
    Posterior mode
   </p>
  </li>
 </ul>
 <h2 level="2">
  Tips for Success
 </h2>
 <p>
  To do well this week, I recommend that you do the following:
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    Review the video lectures a number of times to gain a solid understanding of the key questions and concepts introduced this week.
   </p>
  </li>
  <li>
   <p>
    When possible, provide tips and suggestions to your peers in this class. As a learning community, we can help each other learn and grow. One way of doing this is by helping to address the questions that your peers pose. By engaging with each other, we’ll all learn better.
   </p>
  </li>
  <li>
   <p>
    It’s always a good idea to refer to the video lectures and chapter readings we've read during this week and reference them in your responses. When appropriate, critique the information presented.
   </p>
  </li>
  <li>
   <p>
    Take notes while you read the materials and watch the lectures for this week. By taking notes, you are interacting with the material and will find that it is easier to remember and to understand. With your notes, you’ll also find that it’s easier to complete your assignments. So, go ahead, do yourself a favor; take some notes!
   </p>
  </li>
 </ul>
 <h2 level="2">
  Getting and Giving Help
 </h2>
 <p>
  You can get/give help via the following means:
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    Use the
    <strong>
     <a href="https://courserahelp.zendesk.com/hc/en-us/">
      Learner Help Center
     </a>
    </strong>
    to find information regarding specific technical problems. For example, technical problems would include error messages, difficulty submitting assignments, or problems with video playback. If you cannot find an answer in the documentation, you can also report your problem to the Coursera staff by clicking on the
    <strong>
     Contact Us!
    </strong>
    link available on each topic's page within the Learner Help Center.
   </p>
  </li>
  <li>
   <p>
    Use the
    <strong>
     <a href="https://www.coursera.org/learn/text-mining/discussions/forums/5mcKtywqEeaaVA48G_0dEQ">
      Content Issues
     </a>
    </strong>
    <strong>
    </strong>
    forum to report errors in lecture video content, assignment questions and answers, assignment grading, text and links on course pages, or the content of other course materials. University of Illinois staff and community TAs will monitor this forum and respond to issues
   </p>
  </li>
 </ul>
 <p>
 </p>
</co-content>
<style>
 body {
    padding: 50px 85px 50px 85px;
}

table th, table td {
    border: 1px solid #e0e0e0;
    padding: 5px 20px;
    text-align: left;
}
input {
    margin: 10px;
}
}
th {
    font-weight: bold;
}
td, th {
    display: table-cell;
    vertical-align: inherit;
}
img {
    height: auto;
    max-width: 100%;
}
pre {
    display: block;
    margin: 20px;
    background: #424242;
    color: #fff;
    font-size: 13px;
    white-space: pre-wrap;
    padding: 9.5px;
    margin: 0 0 10px;
    border: 1px solid #ccc;
}
</style>
<script async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$$','$$'], ['$','$'] ],
      displayMath: [ ["\\[","\\]"] ],
      processEscapes: true
    }
  });
</script>
